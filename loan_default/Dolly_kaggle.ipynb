{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert npy to csv, ready for pandas manipulation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = np.load('ecs171train.npy')\n",
    "test = np.load('ecs171test.npy')\n",
    "np.savetxt('pre_test.csv', test, fmt='%s')\n",
    "np.savetxt('pre_train.csv', train, fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "delete_list = [\"b'\", \"'\",\"\\n\"]\n",
    "tmp = open(\"pre_test.csv\")\n",
    "tmp1 =open(\"pre_train.csv\")\n",
    "out = open(\"test.csv\", \"w+\")\n",
    "out1 = open(\"train.csv\", \"w+\")\n",
    "\n",
    "for line in tmp:\n",
    "    for word in delete_list:\n",
    "        line = line.replace(word, \"\")\n",
    "    out.write(line)\n",
    "\n",
    "tmp.close()   \n",
    "out.close()\n",
    "\n",
    "for line in tmp1:\n",
    "    for word in delete_list:\n",
    "        line = line.replace(word, \"\")\n",
    "    out1.write(line)\n",
    "\n",
    "tmp1.close()\n",
    "out1.close()\n",
    "\n",
    "li = 'id'\n",
    "for i in range(1,770):\n",
    "    li += ','+'f'+str(i) + ''\n",
    "\n",
    "\n",
    "def line_prepender(filename, line):\n",
    "    with open(filename, 'r+') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        f.write(line.rstrip('\\r\\n') + '\\n' + content)\n",
    "\n",
    "line_prepender(\"test.csv\",li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score,log_loss, mean_squared_error,mean_absolute_error,confusion_matrix\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "real_test = pd.read_csv(\"test.csv\",dtype= np.float32)\n",
    "real_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = real_train.copy()\n",
    "test = real_test.copy()  \n",
    "#extract member id\n",
    "test_member_id = test[test.columns[0]]\n",
    "test = test.drop('id',axis=1)\n",
    "test = test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_regression_train = train.loc[train['loss'] > 0]\n",
    "\n",
    "\n",
    "y_train = train.loss\n",
    "#binarize data\n",
    "y_train = (y_train > 0.0).astype(int)\n",
    "\n",
    "y_regression_train = x_regression_train.loss\n",
    "\n",
    "x_train = train.drop(['id','loss'], axis=1)\n",
    "x_regression_train = x_regression_train.drop(['id','loss'], axis=1)\n",
    "\n",
    "x_train.columns = test.columns\n",
    "x_regression_train.columns = test.columns\n",
    "\n",
    "\n",
    "#Preprocessing: 1. Drop cols of NA 2. Replace inf with NA 3.Replace NA with median\n",
    "test= test.dropna(axis=1,how='all')\n",
    "x_train= x_train.dropna(axis=1,how='all')\n",
    "x_regression_train = x_regression_train.dropna(axis=1,how='all')\n",
    "\n",
    "\n",
    "x_train.replace([np.inf, -np.inf], np.nan,inplace= True)\n",
    "x_regression_train.replace([np.inf, -np.inf], np.nan,inplace= True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace= True)\n",
    "\n",
    "x_train.fillna(x_train.median(),inplace=True)\n",
    "x_regression_train.fillna(x_regression_train.median(),inplace=True)\n",
    "test.fillna(test.median(),inplace=True)\n",
    "\n",
    "x_regression_train.head() \n",
    "# both x_train ad test have 769 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_corr = x_train.copy()\n",
    "test_copy = test.copy()\n",
    "x_regression = x_regression_train.copy()\n",
    "# Remove duplicate cols by deleting one of every pair of columns that has correlation \n",
    "# of 1 in the upper correlation matrix. From 758 cols down to 675 columns.\n",
    "corr_matrix = X_train_corr.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] == 1.0)] \n",
    "\n",
    "X_train_corr = X_train_corr.drop(X_train_corr[to_drop], axis=1)\n",
    "test_copy = test_copy.drop(test_copy[to_drop], axis=1)\n",
    "x_regression = x_regression.drop(x_regression[to_drop],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_regression = x_regression.drop(x_regression.std()[(x_regression.std() == 0)].index, axis=1)\n",
    "X_train_corr = X_train_corr.drop(X_train_corr.std()[(X_train_corr.std() == 0)].index, axis=1)\n",
    "test_copy = test_copy.drop(test_copy.std()[(test_copy.std()==0)].index,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train_corr.corr().abs()\n",
    "indices = np.where(corr_matrix > 0.996)\n",
    "indices = [(corr_matrix.index[x], corr_matrix.columns[y]) for x, y in zip(*indices)\n",
    "                                        if x != y and x < y]\n",
    "\n",
    "i = 0\n",
    "for pairs in indices:\n",
    "    X_train_corr[pairs[1]+\"-\"+pairs[0]] = X_train_corr[pairs[1]] - X_train_corr[pairs[0]]\n",
    "    test_copy[pairs[1]+\"-\"+pairs[0]] = test_copy[pairs[1]] - test_copy[pairs[0]]\n",
    "    x_regression[pairs[1]+\"-\"+pairs[0]] = x_regression[pairs[1]] - x_regression[pairs[0]]\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "corr_matrix1 = X_train_corr.corr().abs()\n",
    "upper = corr_matrix1.where(np.triu(np.ones(corr_matrix1.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
    "\n",
    "X_train_corr = X_train_corr.drop(X_train_corr[to_drop], axis=1)\n",
    "test_copy = test_copy.drop(test_copy[to_drop], axis=1)\n",
    "x_regression = x_regression.drop(x_regression[to_drop],axis=1)\n",
    "\n",
    "#355 cols\n",
    "print('GD features',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regressor_model = XGBRegressor()\n",
    "Regressor_model.fit(x_regression, y_regression_train , verbose = False)\n",
    "predicted_output = Regressor_model.predict(test_copy)\n",
    "\n",
    "XGBoost_Submission = pd.DataFrame({'id': test_member_id , 'loss': predicted_output})\n",
    "XGBoost_Submission.to_csv('regression.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler().fit_transform(x_train)\n",
    "Test = RobustScaler().fit_transform(test)\n",
    "\n",
    "Y = y_train.values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y ,test_size=0.30,\n",
    "                                                   random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.sklearn.XGBClassifier(\n",
    "    objective=\"binary:logistic\", \n",
    "    learning_rate=0.05, \n",
    "    seed=9616, \n",
    "    max_depth=20, \n",
    "    gamma=10, \n",
    "    n_estimators=500)\n",
    "\n",
    "eval_set = [(X_train, Y_train), (X_test, Y_test)]\n",
    "\n",
    "clf.fit(X_train, Y_train, early_stopping_rounds=10, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_prediction = clf.predict(Test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": test_member_id,\n",
    "        \"loss\": Final_prediction\n",
    "    })\n",
    "submission.to_csv('classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_preds = pd.read_csv('classification.csv')\n",
    "\n",
    "regression_preds = pd.read_csv('regression.csv')\n",
    "\n",
    "#Replace values >0 in classification output with values in regression output\n",
    "classification_preds  = regression_preds.mask(sub['loss']==0,classification_preds )\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
